{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "<h4>Problem statement</h4> \n",
    "<br>\n",
    "<p> The problem we have chosen to model is the Black Friday Purchase Problem in which the objective is to predict the purchase price after being given a variety of categorical and quantative variables. </p>\n",
    "\n",
    "\n",
    "<h4>Background/Data Breakdown</h4>\n",
    "<br>\n",
    "\n",
    "<p> Black Friday is one of the biggest phenomena in the United States and companies for years have been trying to build an effective model in order to release targeted ads to consumers based on previous consumer knowledge. The uniqueness of the problem and the significance of it to the consumer market is what really drove us towards attempting to crack this problem. The data was taken from a machine learning challenge on datahack.com, and it is extremely well maintained. There are 550,000 rows and 13 columns filled with interesting variables such as marital status, gender, stay_in_city, occupation, etc. The data has a unique row id, and then also contains what essentially acts as a foreign key reference with the variables user_id and product_id. These variables are very useful for Exploratory Data Analysis and could potentially help with feature engineering down the road. \n",
    "\n",
    "<h4>Questions and Types of Learning</h4>\n",
    "<br>\n",
    "\n",
    "<p>The learning that we have chosen for this task is supervised learning and within the umbrella of supervised learning we have decided to go for a regression approach since we are trying to predict the purchase amount of a given sale. The two types of regression that we have decided to go with is OLS(Ordinary Least Squares) and the regression variant of the Decision Tree Classifier. The captural all measure, P, that we are using to determine out performance is RMSE(Root Mean Squared Error) which takes the difference between the observed and expected for each data point and then finds the mean of the difference, squares it, and takes the square root. This helps to identify how close and correct the models predictions are.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Initial reading of the training data set in order to see columns\n",
    "'''\n",
    "\n",
    "table = pd.read_csv(\"train.csv\")\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Converting the initial training sets categorical variables into dummy variables\n",
    "'''\n",
    "\n",
    "finalLearningMatrix = pd.get_dummies(table, columns = [\"Gender\",\"Age\",\"Occupation\",\"City_Category\",\"Stay_In_Current_City_Years\",\n",
    "                                                                    \"Marital_Status\",\"Product_Category_1\",\"Product_Category_2\",\n",
    "                                                                    \"Product_Category_3\"],sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setting table_purchase in order to create labels set\n",
    "'''\n",
    "table_purchase = table[\"Purchase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Doing the initial splitting of the data set into training and testing\n",
    "'''\n",
    "train, test, train_labels, test_labels = train_test_split(finalLearningMatrix, table_purchase, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dropping these two features initially in order to establish baseline \n",
    "performance as we are trying to predict Purchase Amount\" \n",
    "'''\n",
    "train = train.drop(columns =[\"Purchase\",\"Product_ID\"])\n",
    "test = test.drop(columns =[\"Purchase\",\"Product_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Linear Regression is our first chosen model\n",
    "'''\n",
    "\n",
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fitting the model with the training set and labels\n",
    "and then creating predictions\n",
    "'''\n",
    "\n",
    "model = lm.fit(train,train_labels)\n",
    "predictions = lm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648023109206612"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model score for the training set\n",
    "Should be a bit higher I think\n",
    "'''\n",
    "model.score(train,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6475401218195727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model score for the test labels\n",
    "Very encouraging performance\n",
    "'''\n",
    "model.score(test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Actual')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X+cVOV96PHPd5dBB2OyUH9URzYYSrFSlFVuWMu9ealtwB9VNyaGGKk2zSvem5u8bkGz90L0liWSQkOTcvNqm1u9tdVKzaLiBIsJctU0LREiZheQRCr+QkZvJIE1Fja6Lt/7x5yzzu7OzzPn58z3/Xrta2fPzpx5nvlxvud5zvN8H1FVjDHGmDC1RF0AY4wxzceCjzHGmNBZ8DHGGBM6Cz7GGGNCZ8HHGGNM6Cz4GGOMCZ0FH2OMMaGz4GOMMSZ0FnyMMcaEbkLUBQjbKaecotOmTYu6GMYYkyjPPPPMz1X1VL/213TBZ9q0aezcuTPqYhhjTKKIyCt+7s+63YwxxoTOgo8xxpjQWfAxxhgTOgs+xhhjQmfBxxhjTOiabrSbMcYkXbYvx9ot+3htYJAz29J0L5xJV0cm6mLVxIKPaWqN8CWuR7Yvx8pH9nLk2BAAbekUPVfPSvRr4L6nuYFBWkUYViXTQO9tti9H94O7GBrOr0KdGxhkSW8/O185zNwPTknM51mabRntuXPnqs3zMZD/Ei/fuIfBoeGRbQIoNNTBqpRsX45bH9jF8PHRx4BUi7D2uvMTWfdi76krnWrl4xdmePK5Q4k4OJfS8ZXHRk4WanH6yRPZcdtHPT+viDyjqnM972Ds/iz4mGZV6UvcSIFobAunGkmrd7Yvx60bdjFc4zFtcWc7q7pmB1Qq/01bttnzYycI7F99pafHWvCpkwWf8pqlG+r27B7u236g5sclsVsq25fjlg39HPfwVU+nWll97ezY17dci6caE1uFr30iGa29eoIPwPtPaGX3ystqfpzfwceu+ZgRY7/AuYFBlm/cA0BXR6Zh+tKzfTlPgQdgYHCIWzb0AySmzrf09nPc42MHh4ZZu2Vf7Ou6dss+z4EH4J1hTcz76rbIvfrl28PccNdTrP/cRX4VyZPAhlqLyFQReVJEfioie0Xkj53tU0Rkq4g87/ye7GwXEfmmiOwXkd0ickHBvm5y7v+8iNxUsP1CEdnjPOabIiJB1acZFPsCDw4Ns6S3nzkrH6P7wV3kBgYBRro2cgODLO3t5/bsntDL69XKR/bW9fjjWv8+wnLDXU95Djyu15z3PM5yPpTxuOa/A3HnR1/VthcO+7CX+gQ5z+dd4FZV/S2gE/iCiJwLLAMeV9UZwOPO3wCXAzOcn5uBb0E+WAErgHnAh4EVbsBy7nNzweNqb0uaEeUOMgODQyOja8ZS4L7tB8j25QIqmb+8XKwNYh9h8OMgk041z3RAP4KYqU5gnypVfV1Vf+zcfgv4KZABrgHuce52D9Dl3L4GuFfztgNtInIGsBDYqqqHVfUIsBW4zPnf+1X1Kc1fuLq3YF/GgzPb0nU9vmdTMloDpjaD79bbdjJmvFBOaURkGtAB7ABOV9XXIR+ggNOcu2WAVwsedtDZVm77wSLbiz3/zSKyU0R2Hjp0qN7qNKzuhTNJp1o9P35gMBmtgbZ0KuoiJEqTjUkyIQk8+IjI+4CHgCWq+stydy2yTT1sH79R9U5Vnauqc0891be1kBpOV0eGj1+YoaXBr5zNOvPkqItgTNMLNPiISIp84FmvqhudzT9zusxwfr/hbD8ITC14+FnAaxW2n1Vku/Eo25fjoWdynobkAkyelIwWxQ9fjP5iqzHNLsjRbgL8LfBTVf1Gwb82Ae6ItZuA7xRsv9EZ9dYJvOl0y20BFojIZGegwQJgi/O/t0Sk03muGwv2ZTyod7jqleed4WNpguNHN9JJE713T4YlKQNATHMKcp7PfOAPgD0i0u9s+zKwBtggIp8FDgDXOf97FLgC2A8cAz4DoKqHReQO4Gnnfl9RVffU9fPA3wNp4LvOj/Go3iG1Tz7XPNfTUq3xHwGWhGHDcWPXA8MTWPBR1X+l+HUZgN8tcn8FvlBiX3cDdxfZvhP47TqKaQqc2Zaua6hpEuaD+OXNBAyuaKb3wy/1tPxNbeJ/+mZC071wZsmzhWrUO1Q7SZJQ1ySUMW7etmHlobHgY0Z0dWS4obO9aACaVGGiYTrVSvfCmcEUzGd+DIxIQl2TUEbTvCz4mFFWdc3mLxbNIdOWRshnNl63aA4/uePykv3hrSKJSD7pWnHVLFKt3tt4izvbE1FXv8qYhJH3lU6OqpWEuvrh/SdEP2DGEouacbo6MkUPXD1XzxqXOTgpWY8LuWV1k6RWa1KqhT+99rxE1XX+9Cl1p9i5obPdp9IE50+vPY8lvf2V71hBEurqBy9Zrf1mLR9Tta6ODKuvnT2qVZS0wOPq6siwbdmlrFs0p+SXwD0LLmz9Ja2u6z93EfOnT/H8eIFErHXT1ZFhxmkn1bWP00+emIi6rls0p67HxyVXn7V8TE1KtYqSyq3L8o27GRzKX2xuEfj0vGQtMFaOmzrfy4JySWoJbL3lYuZ9dSs/e+udmh87f/qUyJcYqJb7me3ZtNdTSqvV157nd5E8scXkjDFAfoG9+3e8yrAqrSJcP29qIgNwYT1cSVx3qlrFFoAs1aU8eVKKvj9Z4Ol5bCXTOlnwMcY0umIru9Z7fdZWMjXGGFNW4aCawhZRnFp+FnyMMaYBxf36rAUfY2Ju7ECBtnSKnqtnxfrAYkwlFnyMiZnCC8gfSKd46+13GS5Y52JgcIjuB3YB/k0k9UOxC99xKp8XpepkJwT1swEHpiEl9UBY7EJxKZm2NNuWXRpCqSorVm4hP1Q7iSPmoLb3AiDVIqy97vxEfM68sAEHxhdJPThXY+xBIzcwyPKNe4B4tRTGyvbluHXDrlFDhMuJU9bqYmtBKXDf9gPct/1AycelUy2sjmHWiNuze8qWu5ih48raLftiV5e4suDThJJ6cK5WsQPh4NBwbA8Mt2f3sH77geJrwJfxgRitPeM1EA4OHR9JixOX98ZL4HHF6YQg7uKRZ8GEauUje4senJf09jN/zROJXwGz1AEgjgcG90DnpfN7aDg+6f/rXb6hZ9Nen0pSv/t3vOr5sSfGJHVNEtgr1WSyfbmy6VVyA4N0P7Ar0QGorcSSCXFc38brGTbA0XeGY3OyUO/yDV7SxASl2m7PYtwUTaYyCz5NppqllYeOa6zORKuR7cvR8ZXHmLZsc8ngevjo25y9bHNsDth+cLtMo66PH11mUdfB1VLnugpxqUfc2TWfJlNt11OczkRLcQdNVLssgntW2mjXuOJ8PasWS3r7WbtlX+SDX06Y0FJXC2ZJbz9Levtt+HUF1vJpMo3SJ+0OmqhlPZ5C7gG7UcTxepYXcej29avrbGBwiCW9/dye3ePL/hpNYxyJTNWqXaO+ReLdfVBsRFutGuWADfG8nuVVErt9y1m//UCsv0tRseDTZI5XeS31uOa7D26466lgC+SRH4GjkQ7Y036tceoCyej2rZZS3bXWZmPBp4l4Ofva9sLhWHYb1Bs4Ui1S9witOPlhnUtl1yuuJylx4bV7uJFZ8GkS7jUSL9bXMRw4KJecc2p9O6hzRFPcRJ0ka1vEwS/uWqXBPnA+sODTJOq5RqLE68w225fjoWfq60MfGlZu3bCr4YZem3gaVg3kM5btyzF/zROJ/Bxb8GkS9V4j2fbC4dh8sP0YbAD5A4ISn7ky9Up6+Rud35+xbF+O7gd3kRsYHPkcdz+YnAniFnyaRKlZ/7WIywikIEapNcLQazc90u3ZPYk9G/ZT3FoFfn/GVj6yl6Hh0R2uQ8PKykfi8T2txCaZNgk/Vs5wRyBFnRH7zLZ0IBdwC4Nati9Hz6a9I3WePCnFiqviP2EwNzA4KmWPnxNqo37fazE2WWtuYJAlvf30bNob6cTPek+cCt+DUl/pI8eGmL/miVi/P2DBp2m86dPQ1Wxfju4HdjHkjNl2JwVCONkCsn053vhlMCOHJrTA/DVPFA1sR44N0f2gv/UM60x8cGiYnk17iy6CBtUF1igyoU9f/ijXz5ta83pA5bJSDwwOFS134UE9SAqeA0Mt6wu5XXAQ3ywetphckyh1UK1VOlU89UhbOkX/igV177+cWhf3CkK9C7iNOsiJPy3Sas2fPqXsqLTFZRZ+m7PysZJzbzIBtUSrKReMfk3bJqXKJs4t1JZOIULV9/eTl4XnvHyHJ09K0fcn/nwvbTE540n3wpkj66bUo1TqkTAmBfo10KAeXg+y+cC5e/TrF/J5X6Xh0G5rYeyBPtuXK/v+Bj2HpVy5CrtGobZAEuVEVjeLQ7XBJ9uX8/Q6RxFYq2UDDkwi3J71nsfNT17ma2T7ctzS25+IdPvFUsHEYSDGfdsPjJrs7LaCk5wJodqy1zNHL84s+DSJOBxAvKpnZUm/eVnrpWfTXsIIO35MYyyWCiYOQR9GL/IWh1ZwWHo2jV/8sVptMVrtdiwLPk3CrwNIqaTYQX7I61lZ0m9eWj5hnZ2f2Zb25X2IS7AZqzDwN0JS2MlVTH+o1OVZSc/Vszw/NmgWfJqEX9k93ndiitSY1bZSLRLoh7yelSX9FqeyjJUbGPQt0Lldb3HK61cY+BshKey5Z5xc8T5J7rGoxIJPE8j25XwbVXXk2BBDx3XkQJBpS9c8aqcWUU8MHCtT40EvbuWvlnvQi1Or8/p5U0duN0JS2GqyhtTbwotz8LLg0wSWb9zt+z6HVUmnWgOfyBa3L0+tB72kzDYfyz3oxbWl19WRqarbKu4qfb7rbeHFuXsysOAjIneLyBsi8mzBth4RyYlIv/NzRcH/lovIfhHZJyILC7Zf5mzbLyLLCrafLSI7ROR5EekVkYlB1SXJsn25wEZZhZGSJk7XH9KplpoDbZyHupYTx26tsYNOVlwV3+sZ1aoUHLoXziSdavW8/zi+j64gWz5/D1xWZPtfqOoc5+dRABE5F/gUMMt5zF+LSKuItAJ/BVwOnAtc79wX4M+cfc0AjgCfDbAuifXlAFo9heJ8ZlWLSgMJWoDV154XTmEiJiSjW6sRWj8TKhyBuzoyrL62tgwPLrdnIq4CCz6q+gOg2kU+rgG+rapvq+pLwH7gw87PflV9UVXfAb4NXCMiAlwKPOg8/h6gy9cKNIhjAc8tifOZVS0qdS99Y9Gc2KYp8ZsS35QsY624alZdLYOoVfP17OrIlLzW2JZOkWlLI87tyZNSCPlrk6uvnR3r9zGKDAdfFJEbgZ3Arap6BMgA2wvuc9DZBvDqmO3zgF8DBlT13SL3NyGJ+5lVLVoEzvhA8TQxmbZ0rL/Epby85kpgfJJNyL93J6ZainYL1jqoIkru++Km1/lAhClzgtS9cOa41FLpVGukSVLrFXbw+RZwB/mTqzuArwN/RPH5cUrxlpmWuX9RInIzcDNAe3t7bSU24wjEPqtxrY5r6S940gPsqq7ZzP3glHEZqYGGqG9XR6bo59DN+Ran64ZejQ2yjfD9CzX4qOrP3NsichfwT86fB4GpBXc9C3jNuV1s+8+BNhGZ4LR+Cu9f7HnvBO6EfGLROqvR9F5yzqgbTSN+wV2lDtDQmPWF9+o8bdnmqIvii3LvYRKFGnxE5AxVfd3582OAOxJuE/CPIvIN4ExgBvAj8ifZM0TkbCBHflDCp1VVReRJ4BPkrwPdBHwnvJo0t2xfrqG+BIUa7QteSSPX1235mHgKLPiIyP3AxcApInIQWAFcLCJzyHeRvQz8ZwBV3SsiG4CfAO8CX1DVYWc/XwS2AK3A3arqTpz4H8C3RWQV0Af8bVB1MaOt3bKvYQ9YpjHEYfkNU15gwUdVry+yuWSAUNWvAl8tsv1R4NEi218kPxrOhKwR+tBNdYTQV37w7PbsHu7f8WpsJ8aa0Ww9H2N8NHap6aRy65GUw3icMp+b6ljwMYbS2bprUWyp6SRKYpdVnHLQmepY8DE187KsQNy978T6Z8o3whoz2b4ct27Ylbiuq6SV11jwMR4UZhduFAM+TEpMeqoht8WTpAN50ke0zTjtpKiLEBnLam1qsriznVVd3nJNxZkf12eSfo3n1g27EtVyc4Nl0N2b6xbN8aVbtphj78R/afWgWMvHVHTSxFa++rF454mqR6pFys7qHzuIoNREzO6FM1nS2x9kUatWy4qm2b4c3Q/Gv6ttbBLRsLo53blQ2b4cX96429d8iUlvLdfDWj6mor1fuSySwBPGQmzpVEvZxfBuz+5haW8/uYFBlPwgguUb98R+kbij77xbdRlXPrKXoeHgAs/izvaRfHFerxamWmXcEgphH7i7OjL85I7LWbdozrhknqVUqm+SW8v1spZPg4nrUN9qWw+F91++0Z8lnN0Em9WWIduX47aH93D0neJn1YNDw/Rs2jvusXG69jA0rFVPBg46CWfhEOjCEJcZ8x64LbCxgXDypBQrrhqfQPPMtuKJYINWKZfc2M/X/DVPFC1nUpauCIoFnwYy9ssbl6G+xYYgL+3tZ0lv/7gDkGvlI3t971Ipl0qm1iSUA4ND49IMBfV6z58+hW0vVLs6yXvi8v6Xcsk5p456/WrNrde9cCZLe/tjMxep1OerWMJaAW7obG/YruxqWPBpIEF3n3hVrG/eLaXbjQWMOgMOMyW+13ktYaUZ+snrb3l6XLUj4lsFovjY3L/j1XGDV2rJNdfVkYnNNbZyGjlhbT0s+DSQuK5hUqlvfnBomFs37GJpbz9ntqU5+va7Ze/vN68XrsO65uD1fa12/EBU5ytxH+Dgp0ZO4OqVDTgwgavm2tOw6sgF/YHBcIOo1+6pOF1Ta0a3Z/25JmiiYcGngaSDmoxQp+6FMz2PcoqzS845NZTnqWXYdDOxlDrJFs+jlalJti/H/DVPMOjj/AM/PbDzQGwuCvtp8+7XK9/JB6eePDGU50maZuq2a0R2zSfhkpAE0stIrSQI6xrb828cDeV5kqZVxAJQglnLJ+EaIZmlMV40Yo7BZmLBJ+GCHnFVbva2MVFqxByDzcSCT8IFPeJqbEoTY/wU9zRFJjgWfBKue+FMWluCG0tmcxMaX5TrM9Wbksha5sllwSfhujoyDB+3i65xkEnovJ8or53U221sLfPksuCTcNZtER/dC2eSTrVGXYyareqazeLO9qrT8fip3m7jro5M2XlQk+qc+2ZzrIJjQ60TZmzm3CNH345VefzMWZVqEYYS1Krr6siw85XDrN+evHlNq7pms6pr9qgEq2EMZfYjq3PP1bPGTTdIp1pZfW1+DaoZX96MlylwLZLftwmGBZ8EKZYdOm7lGZsktB5rrzufpRv6q85RVsrY7NNBevK5Q7EKPGcv21zTScHYHGTZvlzsk3dWStz5rse519/45By75hkgCz4JErc5PcXKMzg07Fu2Z3cf9R78iq2945dal2IIm5svb2lvPztfOVzz8OSgM0f7+VkptR+v6/5Y4AmWXfNJkLgd4EpdLPZz7pEfB4AgE5W6q5wGxa9rDkp+Ube4XSMMIzN498KZpFpru6Blo+iCZ8EnIaI4aMyfPqXodjeXXKnupRYRX8sb56SkQXex+X3NYeUje33dX71CywxewxvV2jJ+yW7jP+t2S4goDhov/2L8WWmppY4LDav6tgQ2BH+Aj6t1i+b43u3lJR9dJsDlqsNYRnrtln01DVyxM/Jw2OucEFEsFFesS6Ta1VLdaz/1TiL0Q1KHy8blmkOQQ8jDqGOtXXtDx5WeTfFqITaiki0fEXmEMiedqnp1ICUysVGsS6SWIOhXf/7kSam6gu/vn3+GL+VoVu4Q8vt3vJrILNIfSKdqvu43MDgU6ijJZlSu2+3PQyuFqajNwxeoHulU67gukVpXjmyblGLSxAl1d9msuGoWS3v7PXe/9f7oQKySUKZahPedOIEBJ6AWq1ecWmvZvhwPPZNLZOABPE+e9WsknimuZPBR1X8OsyCmvFlnnhzqujgfv3D80NVaV45889gQ555xsi/XCya0SlXdfcXEaY29tnSKX/5qqKqWXFzOvOM2xL9WAx5bzWGMxGtmFQcciMgMYDVwLnCiu11VPxRgucwYYS/I9uRzh8Ztq/XM9ziw/cUjdZdl7ZZ9ngNPnLgJPItd+xZGt4AGBod8HbRRj7gN8a+V13k+oY3Ea1LVDDj4O+BbwLvAJcC9wD8EWSgTPb/O+vzoqmmUM9Bh1ZJdp8VeJXfQRtSizHrth2IDJtKpVhZ3tpesmxDOSLxmVk3wSavq44Co6iuq2gNcGmyxTNT8Ouvz48DVKGegJ02sfcRYHAJvUq/1uLo6Mqy+djaZtjRCfuj46mvzuey+/snzxwUmAW7obI9Fl2cjq2aez69EpAV4XkS+COSA04ItlgnDy2uuHJefDYoPNvDq+nlTuW/7gbr20b1w5rgyJtHRd4ZLjtwToWgOO69dRn4Kcp5PWEql36mUF84Ep5qWzxJgEvDfgAuBPwBuCrJQJhzuBe1iZ4Vjv3y1jnRzvXTo3+sup1vGetPjx8GKq2aNS/WSahVumNdetGsoDl0/5bqtkriExFhdHRm2LbuUl9ZcybZll1rgCUnFlo+qPu3c/HfgM8EWx4RpSW8/tz28h6Pv5FsUbelU0bO+bF+O9R5bL34OlDgWp2FrHt2yoX/cgIMJLcLm3a8zODQ8soxBpuAMPOqs0uVaB3M/OCXWiVVNfFUz2u1JilwPVVW77tMA3MAD+RFWS4pkP167ZV+kKW6yfTmWxjytf7WKjXQbHDrOoBNY3esrl5xzaqzOwN1uq2xfjp5Ne1nS28+S3n4mT0px5Xln1N21GpUg16My5VXTj/EloNv5+Z9AP7Cz0oNE5G4ReUNEni3YNkVEtorI887vyc52EZFvish+EdktIhcUPOYm5/7Pi8hNBdsvFJE9zmO+KZLwITkVhNnhdN/2A6O62aK86J3ty9H9wK6my+8WxwzU7ntROGLvyLGhRAee5Rv3kBsYHFl6YvnGPbF73RtVxWOaqj5T8LNNVW8B5lWx778HLhuzbRnwuKrOAB53/ga4HJjh/NxMfmg3IjIFWOE834eBFW7Acu5zc8Hjxj5Xw8j25Qi7w2l9wcHvA3XMti+VGbtatSaFbCRxGGbtyvbluHXDroZ4L9ys7Et6+0uuR2WCVzH4OK0V9+cUEVkI/Hqlx6nqD4CxHf7XAPc4t+8Bugq236t524E2ETkDWAhsVdXDqnoE2Apc5vzv/ar6lKoq+blHXTSoKDJaK+8d/OppU67/3EV1lSMOQ42jEpe6uy2EpA+5htGtnVLi8ro3umqGWj9D/lgk5CeavgR81uPzna6qrwOo6usi4g7ZzgCFuVsOOtvKbT9YZHtRInIz+VYS7e3tHosenSgyWsN7X0Kv6Un8EIehxlGJy/ympKfXKbTykb0V6xKX173RVXMp4bdU9UOqeraqzlDVBcDTFR9Vm2Ln1uphe1GqeqeqzlXVuaeeeqrHIjYft7styi9jHIYaR+WSc+LxWW2UlkC2L1fxRC4uw9ubQTXB54dFtj3l8fl+5nSZ4fx+w9l+EJhacL+zgNcqbD+ryHbjI7e7LcovYzOPPHromVwsLn43Skug0ho9InDChBaW9vYzf80TsXjtG1nJ4CMivy4iFwJpEekQkQucn4vJTzr1YhPvTVC9CfhOwfYbnVFvncCbTvfcFmCBiEx2BhosALY4/3tLRDqdUW43FuzL+MQ9S+zqyJD2OMHTjy9wpkEOfrVyL35HPbU2yMXkwpLty1VckkQ1P93ARr6Fo9w1n4XAH5JvVXyd97q6fgl8udKOReR+4GLgFBE5SH7U2hpgg4h8FjgAXOfc/VHgCmA/cAxnMquqHhaRO3ivm+8rquoOYvg8+RF1aeC7zo/xUUtB5+avPE7w9GOCZPfCmZFPtIzKa84w4CgVTjJN6vU3LyPY3ODfzK3vIJVbz+ce4B4R+biqPlTrjlX1+hL/+t0i91XgCyX2czdwd5HtO4HfrrVccVRpoluLFJ+cGLTC54zywn9XR6auxeSSLC4DLtxJpmcv25zI98HrdatGud4VR9W06C8UkTb3D6cLbFWAZWoq1Ux0i8PUiqgvwsbgJQhdHC9++3n9Z3FneCNPy5U705Zm8qTic9ka5XpXHFUTfC5X1QH3D2e+zRXBFam5FBvGOjg0zK0bdo0EoKiueRQOKYy666ERkorWolSC16j5ef0nzKXNSyVHXbdoDtuWXcqKq2bFNrFro6rmG90qIie4f4hIGjihzP1NDUo164dVWdLbzw13PRXZF2Bsa6OtjkwHtRo7sXWwAZKKAqxbNGckg3hbOjUuw3XhAdENPF4HewRhbBb0tnSK1pbaZyGHXaVK2durze5u/FPNJNP7gMdF5O+cvz/De1kKTJ0q9elve+EwPwx5CW3X2BZXz9WzimZlDsIN80Z3yQT5lKXW2PFbWzo1bl2ZahJbrr72vFgNuChWh1rLt/a6OX4Xq6JSa/pU+3/jr2qWVPiaiOwGfo98T8z3gA8GXbBmUc1CaVFc7yjW5eB+MYM+EE5KtbB++wGefO6QL1mGK7XYVlwVTlDtuXrWuG3VHPC6OjI8sPOAL8tTBNF96Za/1KCQkya2kmpt4c3BIcscbUZU0/IB+H/AceCT5NPr1Dz6zRTX1ZFh5yuHfc0MPOO0k9j/xlHPQStT5ABReIYedEvBXbfHHXxRjxaKH/QLhRFUZ5x2Ul0H3PWfu4hZf/K9UUtg1KpF4E+vPc/z48tx67bykb0jn422dIqeq2dZoDFFiZZIFigivwl8Crge+AXQC3xJVRPd6pk7d67u3FlxRYjQZPtyvp11t4pw/byprOqaPZKF2EsyyJfXXDmujH4vY92WTjE0fLyqg6nXZZwnpVoYGj6Oe7moReDT89pLXuietmxzTftf3Nle1UnD/OlT6k6wCsXfByHfMp6Uahm12J4AvzN9Ci//YtDWqjG+EJFnVHWuX/sr1/J5DvgX4CpV3e88+VK/ntjkrd2yr+rA4x4879/xKsOqo4JNoWxfjtse9i8LcRCJJftXLGDOyseAyvv1EnjWLZozriVzXPPr5Lx06N99CQarumaPrOQZxgGyz9rGAAASHElEQVS+3IqixiRNueDzcfItnydF5HvAtyme0NN4lO3L1XRgPWFCC6u6ZpcdoupnS8oV1ES7SulOXO7ZfS3KrXy67YXDfPQb32frLRfXuNfxwr5IbRfFTaMoefVRVR9W1UXAOcD3gaXA6SLyLRFZEFL5Gpa7KmQtqhluvPKRvb5fOI96op2X6lR6zPNvHOWGu7zmxzXG1KualUyPqup6Vf198nne+nlvBVLjUVArdAYxEKBRJ9r5MXrMGONNTeMunRVF/0ZVLw2qQM3CckYZY5pZfKZON5mgurKCuChna9obY/xmwSciQa1SGcQ8yThkVTbGNBYLPhF58rlDURfBGGMiY8EnInbNxxjTzCz4RCTq4cvGGBMlCz4RCWL4sq03b4xJCgs+DWT5xt1RF8EYY6piwSciQWRQbpQF14wxjc+CjzHGmNBZ8DHGGBM6Cz7GGGNCZ8HHGGNM6Cz4GGOMCZ0FH2OMMaGz4JMgrQ2yjmxbOhV1EYwxEbPgkyBf/+ScqIvgi56rZ9X8mMWd7QGUJPznMMbkWfBJiMWd7XR1ZAJ/nsmTgm+VeKnHqq7ZAZRk/HNU27ic2CjNUGMiYsEnAdYtmhPKwRdgxVW1t0pqsW6R99ZbGC2TG6p8jq994vyAS2JMY7PgkwBhtHjAn9ZVqkSLQHzY/6qu2cyfPqXsfVpb6muRrOqazeLOdlql9H7CaoUa08gs+DSxTFsacX771bpa+4nzyTjLRbgH8Exbmr/waf/rP3cR6xbNGTVowY03mbY0X7+u/hbJqq7ZvLD6Cl5ecyXrFs0J5HUyptlNiLoAJjrbll0K5JdiWLtlH0t7+zmzLU33wpmez+y7OjKBtwoqPYefSVvDqI8xzciCT5PL9uW49YFdDB9XAHIDgyzp7WdJbz8tAp+eV9t1ltuze1i/4wCqo7enWmDtdXM8H8inLds8crstnaLn6lkWFIxJMAs+Icv25fjvD+7yZV833PUU2144XNc+bnt4z0jgGeu4wn3bD9S0v1L3Hzr+Xouk3qAxMDjk276MMdGwaz4hyvblWNLbzzvDxQ/2tfjoN75fd+ABOPrOcN37qEXPpr2+7evLtnieMYllwSdEtz28x5f9ZPtyPP/GUV/2FbaBwSHf9nXMFs8zJrEiCT4i8rKI7BGRfhHZ6WybIiJbReR55/dkZ7uIyDdFZL+I7BaRCwr2c5Nz/+dF5KYo6lILv1oZfgUxY4yJSpQtn0tUdY6qznX+XgY8rqozgMedvwEuB2Y4PzcD34J8sAJWAPOADwMr3IAVR7dn/QsYfgSxGaed5ENJjDHGmzh1u10D3OPcvgfoKth+r+ZtB9pE5AxgIbBVVQ+r6hFgK3BZ2IWu1v07XvX0uDrnTJZ07B3rsjLGRCeq4KPAYyLyjIjc7Gw7XVVfB3B+n+ZszwCFR+6DzrZS22NpeOzY4yrVOtS5Wq8NDAay3ziolAXBGBO9qILPfFW9gHyX2hdE5CNl7lvs3F/LbB+/A5GbRWSniOw8dOhQ7aWNgEg+jUtQs+nPdLIQRCmo5JzrP3dRVfez1KDGRCeSeT6q+prz+w0ReZj8NZuficgZqvq60632hnP3g8DUgoefBbzmbL94zPbvl3i+O4E7AebOnVv/OOeArVvkfTJmNVKtQvfCmf7us0UYKjFfqJQhH4acl9KWTlUcWRf7D4IxDSz0lo+InCQiJ7u3gQXAs8AmwB2xdhPwHef2JuBGZ9RbJ/Cm0y23BVggIpOdgQYLnG2J52fgGZsHbfKkFGs/cb6n53BztbWKMH/6lFE5z9Z6yKkWZOur5+pZpCpcMMvEoPVnTLOKouVzOvCw5A9kE4B/VNXvicjTwAYR+SxwALjOuf+jwBXAfuAY8BkAVT0sIncATzv3+4qq1j/rssH4mZvshdVXlP1/rTnVuhfOZPnGPQwOvTd6L51qHfW3V26d127ZR25gEGF0SyedavW99WeMqV7owUdVXwTGnSar6i+A3y2yXYEvlNjX3cDdfpcxatOWbaZVhOvnTR13zSfbl6tpX2cv21x3stCgFAaI1wYGR8rpV2LQwsDrJk8tfJ64vR7GNBPL7RZTw6ojedLcAOSm56mFkk8W2v1APp9c3A64xVpmfmalLvc8xpjoxGmejynivu0HRlo7S+s4KA8dV1/zqhljTD2s5eOjUl07tXaVjeW2BOodneVnXjVjjKmHBR+fZPtyoy6e5wYGWb4xn1Jn7ZZ9de+/mVot86dP8SVjtzEmvqzbzSe3Pbxn3CitwaHhkZZQvfxqtZy9bDPz1zxRd2ssSNVOErX8dMYkl7V8fHB7dk/JZJ+5gUEmT0px5Fg8urxGBiDUuKBdHOfEbL3l4qiLYIzxyFo+PlhfZrVPAX7lw7wVvw0NKysf2cvizupyx1UzJ6aaAOVOVK33fusWzalqP8aYeLLg44NyAwEUGIzpomdHjg2xqmt2xUSc1ab76V44s2K+tOvnTa1wj8r3W9zZbsOmjUk4Cz6G9Z+7qGgLKNUiNeWZ6+rIcENne9EAJNSWKHVV12wWd7aPWlIinWph3aI5gSVbNcaER9Rjqv+kmjt3ru7cudPXfU5bttnX/YXp5TVXjtz2KwuAZRMwpvGIyDMFi3/WzQYcmBF+ZQGwbALGmEqs280YY0zoLPgYY4wJnQWfOsV5sqYxxsSVBZ86+ZE6xxhjmo0Fnzr5kTrHGGOajQWfOp2YspfQGGNqZUOtPSicx9Jcs6SMMcYfFnxqNHbpBGOMMbWzPqMard2yzwKPMcbUyYJPjWyAgTHG1M+CT43OjOG6Nl5VymZtjDFBseBTo2rWtUmC+dOnVL1iqDHG+M0GHNSoqyPD0t7+xI5yK8xibYwxUbGWT42yfbnEBh5jjIkLCz416tm0N+oiGGNM4lnwqdHA4FDURTDGmMSz4GOMMSZ0FnyqlO3L0fGVx6IuhjHGNAQLPlXI9uXofnAXR45F1+U2qYoEppkGmoNkjGlsFnyq0LNpL0PD0Y5xGxw6XvE+leYgtaVTfhXHGGPqYsGngmxfLhaDDKrJrNDVkSn7/56rZ/lVHGOMqYsFnwpWPhKPodV+ZFaoFJyMMSYsFnwqiPI6j6tVqg8crSI1bTfGmChY8EmA487lpnLXbE6a2ArA9fOmFv1/qe3GGBMFy+2WAO71nnKNl69+bDYAq7ryv+/f8SrDqrSKcP28qSPbjTEmDiz4xFw61TpyvWegTBdgYbfcqq7ZFmyMMbFm3W4xs7iznUxbGiE/b2f1tbNHAkupEW82v8cYkzSJb/mIyGXA/wJagf+jqmsiLlLNhHxg6V44s+zAgu6FM1m+cc+oZbwLW0bGGJMUiQ4+ItIK/BXwUeAg8LSIbFLVn0Rbsuot7myvuovMDUxrt+zjtYHBqgKWMcbEUaKDD/BhYL+qvgggIt8GrgFiGXwWd7bXPRCgqyNjwcYYk3hJDz4Z4NWCvw8C88beSURuBm4GaG9vD6dkRdhAAGOMyUv6gINig4/HJWFT1TtVda6qzj311FNDKJYxxphykh58DgKFsyfPAl6LqCxlLe6MrsVljDFxk/Tg8zQwQ0TOFpGJwKeATRGXaZRWkZoGFRhjTDNI9DUfVX1XRL4IbCE/1PpuVY1FJtBMW5ptyy6NuhjGGBNLiQ4+AKr6KPBo1OUoJPiThdoYYxpV0rvdYkeAGzrbbTi0McaUkfiWT5TSqRY+fuFZPPncIZv0aYwxNbDgU8EEgXdLrKD90zsuD7cwxhjTIKzbrYL9q69kwpjZRBMEXl5zZTQFMsaYBmAtnyrsX22Bxhhj/GQtH2OMMaGz4GOMMSZ0FnyMMcaEzoKPMcaY0FnwMcYYEzpRLTGJpUGJyCHgFY8PPwX4uY/FSZJmrjs0d/2bue7Q3PUvrPsHVdW3NWmaLvjUQ0R2qurcqMsRhWauOzR3/Zu57tDc9Q+y7tbtZowxJnQWfIwxxoTOgk9t7oy6ABFq5rpDc9e/mesOzV3/wOpu13yMMcaEzlo+xhhjQmfBpwoicpmI7BOR/SKyLOry+ElEXhaRPSLSLyI7nW1TRGSriDzv/J7sbBcR+abzOuwWkQsK9nOTc//nReSmqOpTjojcLSJviMizBdt8q6uIXOi8lvudx47Jhx6tEvXvEZGc8/73i8gVBf9b7tRln4gsLNhe9PsgImeLyA7ndekVkYnh1a48EZkqIk+KyE9FZK+I/LGzveHf/zJ1j/a9V1X7KfMDtAIvAB8CJgK7gHOjLpeP9XsZOGXMtq8By5zby4A/c25fAXyX/IKtncAOZ/sU4EXn92Tn9uSo61akrh8BLgCeDaKuwI+Ai5zHfBe4POo6V1H/HuBLRe57rvNZPwE42/kOtJb7PgAbgE85t/838Pmo61xQnzOAC5zbJwP/5tSx4d//MnWP9L23lk9lHwb2q+qLqvoO8G3gmojLFLRrgHuc2/cAXQXb79W87UCbiJwBLAS2quphVT0CbAUuC7vQlajqD4DDYzb7Ulfnf+9X1ac0/w28t2BfsVCi/qVcA3xbVd9W1ZeA/eS/C0W/D85Z/qXAg87jC1/LyKnq66r6Y+f2W8BPgQxN8P6XqXspobz3FnwqywCvFvx9kPJvXNIo8JiIPCMiNzvbTlfV1yH/wQVOc7aXei2S/Br5VdeMc3vs9iT4otO1dLfb7UTt9f81YEBV3x2zPXZEZBrQAeygyd7/MXWHCN97Cz6VFeu3baQhgvNV9QLgcuALIvKRMvct9Vo04mtUa12T+hp8C5gOzAFeB77ubG/I+ovI+4CHgCWq+stydy2yLdH1L1L3SN97Cz6VHQSmFvx9FvBaRGXxnaq+5vx+A3iYfNP6Z043As7vN5y7l3otkvwa+VXXg87tsdtjTVV/pqrDqnocuIv8+w+11//n5LumJozZHhsikiJ/8F2vqhudzU3x/here9TvvQWfyp4GZjijOSYCnwI2RVwmX4jISSJysnsbWAA8S75+7iiem4DvOLc3ATc6I4E6gTedrootwAIRmew03Rc425LAl7o6/3tLRDqdPvAbC/YVW+6B1/Ex8u8/5Ov/KRE5QUTOBmaQv6Be9PvgXOd4EviE8/jC1zJyznvyt8BPVfUbBf9q+Pe/VN0jf++jHomRhB/yI1/+jfxIj9uiLo+P9foQ+REru4C9bt3I9+E+Djzv/J7ibBfgr5zXYQ8wt2Bff0T+wuR+4DNR161Efe8n370wRP4s7rN+1hWY63yBXwD+EmcSd1x+StT/H5z67XYOOmcU3P82py77KBi5Ver74HyefuS8Lg8AJ0Rd54Ky/UfyXUG7gX7n54pmeP/L1D3S994yHBhjjAmddbsZY4wJnQUfY4wxobPgY4wxJnQWfIwxxoTOgo8xxpjQWfAxpgYiMuxkAH5WRB4QkUl17OtiEfkn5/bVUiZjuoi0ich/9fAcPSLyJa9lNCYoFnyMqc2gqs5R1d8G3gH+S+E/nUmJNX+vVHWTqq4pc5c2oObgY0xcWfAxxrt/AX5DRKY5a6X8NfBjYKqILBCRp0Tkx04L6X0wsh7KcyLyr8C17o5E5A9F5C+d26eLyMMissv5+R1gDTDdaXWtde7XLSJPO4khVxbs6zbJr7nyf4GZob0axtTAgo8xHjh5rC4nP0Mc8gf5e1W1AzgK3A78nuaTtu4EbhGRE8nn0LoK+E/Ar5fY/TeBf1bV88mvv7OX/FozLzitrm4RWUA+7cmHySeGvFBEPiIiF5JPe9JBPrj9B5+rbowvJlS+izGmQFpE+p3b/0I+Z9aZwCuaX/cF8ouPnQtsy6fVYiLwFHAO8JKqPg8gIvcBNzPepeRzg6Gqw8CbBenuXQucnz7n7/eRD0YnAw+r6jHnORoiD6FpPBZ8jKnNoKrOKdzgBJijhZvILzh2/Zj7zcG/NPsCrFbVvxnzHEt8fA5jAmPdbsb4bzswX0R+A0BEJonIbwLPAWeLyHTnfteXePzjwOedx7aKyPuBt8i3alxbgD8quJaUEZHTgB8AHxORtJOx/Cqf62aMLyz4GOMzVT0E/CFwv4jsJh+MzlHVX5HvZtvsDDh4pcQu/hi4RET2AM8As1T1F+S78Z4VkbWq+hjwj8BTzv0eBE7W/HLJveQzFz9EvmvQmNixrNbGGGNCZy0fY4wxobPgY4wxJnQWfIwxxoTOgo8xxpjQWfAxxhgTOgs+xhhjQmfBxxhjTOgs+BhjjAnd/wcSJZJsguXM9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_labels,predictions)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5023.076681975689"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Standard Deviations of the test labels\n",
    "RMSE should be less than this\n",
    "'''\n",
    "test_labels.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2982.1077790815484"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The root mean squared error of our model on the test labels\n",
    "This is encouraging\n",
    "'''\n",
    "np.sqrt(mean_squared_error(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading the data with only purchase dropped this time. We keep the product_ID\n",
    "This shouldnt be too big of an issue because we are trying to find total purchase amount\n",
    "not individual product price\n",
    "'''\n",
    "table3 = pd.read_csv(\"train.csv\")\n",
    "table3 = table3.drop(columns =[\"Product_Category_2\",\"Product_Category_3\"])\n",
    "noNullID = pd.get_dummies(table3, columns = [\"Gender\",\"Age\",\"Occupation\",\"City_Category\",\n",
    "                                          \"Stay_In_Current_City_Years\",\"Marital_Status\",\n",
    "                                          \"Product_Category_1\",\"Product_ID\"],sparse = True)\n",
    "table_purchase3 = noNullID[\"Purchase\"]\n",
    "train3, test3, train_labels3, test_labels3 = train_test_split(noNullID, table_purchase3, test_size = .3)\n",
    "train3 = train3.drop(columns =[\"Purchase\"])\n",
    "test3 = test3.drop(columns =[\"Purchase\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Age_0-17</th>\n",
       "      <th>Age_18-25</th>\n",
       "      <th>Age_26-35</th>\n",
       "      <th>Age_36-45</th>\n",
       "      <th>Age_46-50</th>\n",
       "      <th>Age_51-55</th>\n",
       "      <th>Age_55+</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_ID_P0098942</th>\n",
       "      <th>Product_ID_P0099042</th>\n",
       "      <th>Product_ID_P0099142</th>\n",
       "      <th>Product_ID_P0099242</th>\n",
       "      <th>Product_ID_P0099342</th>\n",
       "      <th>Product_ID_P0099442</th>\n",
       "      <th>Product_ID_P0099642</th>\n",
       "      <th>Product_ID_P0099742</th>\n",
       "      <th>Product_ID_P0099842</th>\n",
       "      <th>Product_ID_P0099942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358658</th>\n",
       "      <td>1001246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54737</th>\n",
       "      <td>1002367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371300</th>\n",
       "      <td>1003227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332421</th>\n",
       "      <td>1003261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70913</th>\n",
       "      <td>1004884</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3692 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID  Gender_F  Gender_M  Age_0-17  Age_18-25  Age_26-35  \\\n",
       "358658  1001246         0         1         0          1          0   \n",
       "54737   1002367         1         0         0          0          1   \n",
       "371300  1003227         1         0         0          0          1   \n",
       "332421  1003261         0         1         0          0          0   \n",
       "70913   1004884         0         1         0          0          0   \n",
       "\n",
       "        Age_36-45  Age_46-50  Age_51-55  Age_55+         ...           \\\n",
       "358658          0          0          0        0         ...            \n",
       "54737           0          0          0        0         ...            \n",
       "371300          0          0          0        0         ...            \n",
       "332421          0          1          0        0         ...            \n",
       "70913           1          0          0        0         ...            \n",
       "\n",
       "        Product_ID_P0098942  Product_ID_P0099042  Product_ID_P0099142  \\\n",
       "358658                    0                    0                    0   \n",
       "54737                     0                    0                    0   \n",
       "371300                    0                    0                    0   \n",
       "332421                    0                    0                    0   \n",
       "70913                     0                    0                    0   \n",
       "\n",
       "        Product_ID_P0099242  Product_ID_P0099342  Product_ID_P0099442  \\\n",
       "358658                    0                    0                    0   \n",
       "54737                     0                    0                    0   \n",
       "371300                    0                    0                    0   \n",
       "332421                    0                    0                    0   \n",
       "70913                     0                    0                    0   \n",
       "\n",
       "        Product_ID_P0099642  Product_ID_P0099742  Product_ID_P0099842  \\\n",
       "358658                    0                    0                    0   \n",
       "54737                     0                    0                    0   \n",
       "371300                    0                    0                    0   \n",
       "332421                    0                    0                    0   \n",
       "70913                     0                    0                    0   \n",
       "\n",
       "        Product_ID_P0099942  \n",
       "358658                    0  \n",
       "54737                     0  \n",
       "371300                    0  \n",
       "332421                    0  \n",
       "70913                     0  \n",
       "\n",
       "[5 rows x 3692 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Making sure training set was created correctly\n",
    "'''\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating Sparse matrices for efficiency purposes\n",
    "'''\n",
    "import scipy\n",
    "sparseTrain = scipy.sparse.csr_matrix(train3.values)\n",
    "sparseTest = scipy.sparse.csr_matrix(test3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Making another regression model for our new sets \n",
    "with added features\n",
    "'''\n",
    "reg3 = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640815375283785"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Running OLS with addition of product_id as a feature\n",
    "'''\n",
    "model2 = reg3.fit(sparseTrain,train_labels3)\n",
    "predictions2 = reg3.predict(sparseTest)\n",
    "model2.score(sparseTest,test_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2906.8805217425556"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Measurement of RMSE for this new model\n",
    "'''\n",
    "np.sqrt(mean_squared_error(predictions2, test_labels3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Trying a different sort of regression model\n",
    "Decision Tree Regression. \n",
    "'''\n",
    " \n",
    "Decision_Model = tree.DecisionTreeRegressor()\n",
    "Decision_Model.fit(sparseTrain, train_labels3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decision_Model.score(sparseTrain,train_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Predicting with the decision tree model\n",
    "'''\n",
    "predicted_Decision = Decision_Model.predict(sparseTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5296051793206842"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Finding the model score/R^2\n",
    "'''\n",
    "Decision_Model.score(sparseTest,test_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3439.865885743178"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RMSE of Decision Tree\n",
    "'''\n",
    "np.sqrt(mean_squared_error(predicted_Decision, test_labels3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5023.076681975689"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dropping User_ID in order to see if this makes a difference\n",
    "in model performance\n",
    "'''\n",
    "\n",
    "table4 = pd.read_csv(\"train.csv\")\n",
    "table4 = table4.drop(columns =[\"Product_Category_2\",\"Product_Category_3\"])\n",
    "noNullID = pd.get_dummies(table4, columns = [\"Gender\",\"Age\",\"Occupation\",\"City_Category\",\n",
    "                                          \"Stay_In_Current_City_Years\",\"Marital_Status\",\n",
    "                                          \"Product_Category_1\",\"Product_ID\"],sparse = True)\n",
    "table_purchase4 = noNullID[\"Purchase\"]\n",
    "train4, test4, train_labels4, test_labels4 = train_test_split(noNullID, table_purchase4, test_size = 0.3)\n",
    "train4 = train4.drop(columns =[\"Purchase\", \"User_ID\"])\n",
    "test4 = test4.drop(columns =[\"Purchase\", \"User_ID\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Age_0-17</th>\n",
       "      <th>Age_18-25</th>\n",
       "      <th>Age_26-35</th>\n",
       "      <th>Age_36-45</th>\n",
       "      <th>Age_46-50</th>\n",
       "      <th>Age_51-55</th>\n",
       "      <th>Age_55+</th>\n",
       "      <th>Occupation_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_ID_P0098942</th>\n",
       "      <th>Product_ID_P0099042</th>\n",
       "      <th>Product_ID_P0099142</th>\n",
       "      <th>Product_ID_P0099242</th>\n",
       "      <th>Product_ID_P0099342</th>\n",
       "      <th>Product_ID_P0099442</th>\n",
       "      <th>Product_ID_P0099642</th>\n",
       "      <th>Product_ID_P0099742</th>\n",
       "      <th>Product_ID_P0099842</th>\n",
       "      <th>Product_ID_P0099942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79537</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232505</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447139</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348104</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3691 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender_F  Gender_M  Age_0-17  Age_18-25  Age_26-35  Age_36-45  \\\n",
       "79537          0         1         0          0          0          0   \n",
       "2968           0         1         0          0          1          0   \n",
       "232505         1         0         0          1          0          0   \n",
       "447139         0         1         0          1          0          0   \n",
       "348104         0         1         0          0          1          0   \n",
       "\n",
       "        Age_46-50  Age_51-55  Age_55+  Occupation_0         ...           \\\n",
       "79537           0          1        0             0         ...            \n",
       "2968            0          0        0             0         ...            \n",
       "232505          0          0        0             0         ...            \n",
       "447139          0          0        0             0         ...            \n",
       "348104          0          0        0             0         ...            \n",
       "\n",
       "        Product_ID_P0098942  Product_ID_P0099042  Product_ID_P0099142  \\\n",
       "79537                     0                    0                    0   \n",
       "2968                      0                    0                    0   \n",
       "232505                    0                    0                    0   \n",
       "447139                    0                    0                    0   \n",
       "348104                    0                    0                    0   \n",
       "\n",
       "        Product_ID_P0099242  Product_ID_P0099342  Product_ID_P0099442  \\\n",
       "79537                     0                    0                    0   \n",
       "2968                      0                    0                    0   \n",
       "232505                    0                    0                    0   \n",
       "447139                    0                    0                    0   \n",
       "348104                    0                    0                    0   \n",
       "\n",
       "        Product_ID_P0099642  Product_ID_P0099742  Product_ID_P0099842  \\\n",
       "79537                     0                    0                    0   \n",
       "2968                      0                    0                    0   \n",
       "232505                    0                    0                    0   \n",
       "447139                    0                    0                    0   \n",
       "348104                    0                    0                    0   \n",
       "\n",
       "        Product_ID_P0099942  \n",
       "79537                     0  \n",
       "2968                      0  \n",
       "232505                    0  \n",
       "447139                    0  \n",
       "348104                    0  \n",
       "\n",
       "[5 rows x 3691 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating sparse matrices\n",
    "'''\n",
    "import scipy\n",
    "sparseTrain = scipy.sparse.csr_matrix(train4.values)\n",
    "sparseTest = scipy.sparse.csr_matrix(test4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setting up linear regression model\n",
    "'''\n",
    "reg4 = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7174659503972384"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Fitting the model and finding the R^2\n",
    "It went up when User_ID was thrown out as a feature!!!\n",
    "'''\n",
    "model7 = reg4.fit(sparseTrain,train_labels4)\n",
    "predictions7 = reg4.predict(sparseTest)\n",
    "model7.score(sparseTest,test_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS(np.asarray(train_labels4), np.asarray(train4)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2671.304088629652"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RMSE\n",
    "'''\n",
    "np.sqrt(mean_squared_error(predictions7, test_labels4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969986833016741"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Running Tree regression with the new feature \n",
    "to see if anything else has changed\n",
    "Score is for training\n",
    "'''\n",
    "Decision_Model2 = tree.DecisionTreeRegressor()\n",
    "# Train the model using the training sets and check score\n",
    "Decision_Model2.fit(sparseTrain, train_labels4)\n",
    "Decision_Model2.score(sparseTrain, train_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5160003800765625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Score for testing\n",
    "'''\n",
    "Decision_Model2.score(sparseTest,test_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedDecision3 = Decision_Model2.predict(sparseTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3496.314102996026"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RMSE for new model\n",
    "'''\n",
    "np.sqrt(mean_squared_error(predictedDecision3, test_labels4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer as to why there are no extensive summary statistics\n",
    "<br>\n",
    "<p>We attempted to run summary statistics on our OLS regressions, but we were unable to get the coefficients of variables in order to perform significance testing and estimate the partial effects. This occured because scikit learn does not have a metrics package for its regression, so we attempted to use STATS MODELS but that package didn't accept scipy sparse matrices as a parameter so it was unable to run on the given computing power </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Machine Learning Process (Code Above)\n",
    "\n",
    "<h4>Data Processing</h4>\n",
    "<br>\n",
    "<p>We dropped Product Category 2 and 3 because of the large amount of Null values present in this that was throwing off our categorical variables. We then used Pandas.get_dummies to convert all categorical variables to dummy variables in order make it conducive to regressions. We then split into a training and testing set as well as training and testing labels.</p>\n",
    "\n",
    "<h4>Model 1: OLS with Product_ID dropped</h4>\n",
    "<br>\n",
    "\n",
    "<p>In this first model we used OLS to run a linear regression on the data set which had Product_ID dropped. Our model score was .648 which means that the R^2 coefficient wa .648. This means that 64.8 % of the variation in the purchase price can be explained by the dependent variables. Additionally, the RMSE for this model was 2,891 which seems like a large amount, but in the context of the standard deviation for the test labels which was 5030 this is an excellent RMSE. The goal from here is to hopefully reduce the RMSE by feature engineering</p>\n",
    "\n",
    "\n",
    "<h4>Model 2: OLS with Product_ID Added</h4>\n",
    "<br>\n",
    "\n",
    "<p>In this second model we used OLS to run a linear regression on the data set which had Product_ID added back in. Although this may seem counterintuitive in that product id usually determines the price this was not the case with our data set because data had been agglomerated over the period of a couple years which meant that products were markdown differently over different years. Our model score was .665 which means that the R^2 coefficient was .665. This means that 66.5 % of the variation in the purchase price can be explained by the dependent variables. This was a slight step up from our previous R^2 of .64, so this was a success for the most part. Additionally, the RMSE for this model was 2,908 which seems like a large amount, but in the context of the standard deviation for the test labels which was 5030 this is an excellent RMSE. The goal from here is to hopefully reduce the RMSE by feature engineering</p>\n",
    "\n",
    "<h4>Model 3: DecisionTreeRegressor with Product_ID Added</h4>\n",
    "<br>\n",
    "\n",
    "<p>In this third model we used a DecisionTreeRegressor to run a regression on the data set which had Product_ID added back in. Our model score was .533. This was a significant step down from Model 2's R^2 of .66, so this was a success for the most part. Additionally, the RMSE for this model was 3,432 which seems like a large amount, but in the context of the standard deviation for the test labels which was 5022 this is an excellent RMSE. However, this was a significant step down from out RMSE of 2,891 which we achieved in model 1. </p>\n",
    "\n",
    "<h4>Model 4: OLS with Product_ID Added, User_ID Dropped</h4>\n",
    "<br>\n",
    "\n",
    "<p>In this fourth model we used OLS to run a regression on the data set which had the User_ID dropped. Our model score was .724. This was a significant step up from both Model 1 and 2, so this was a success. Additionally, the RMSE for this model was 2,676 which was our lowest RMSE yet, but in the context of the standard deviation for the test labels which was 5022 this is an excellent RMSE. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why it matters?\n",
    "\n",
    "Creating a machine learning model that can accurately predict the purchase amount from data about the buyer can be very useful for comapnies. Since the data we are analyzing is from black friday sales, the biggest shopping day in the US, it can better inform companies how much people are willing to pay for a certain product based on information about them. Since a lot of the categorical data we had was masked, we cant exactly specify which types of products people are willing to spend on. However, since the organization who realeased this data does know what the masked values map to, this information can be used to effectively target certain groups of people based on the products and purchase amount. \n",
    "\n",
    "This can help companies determine how much to markdown the product, while still being able to make the most money. Marking down the products to aggressivly or not aggressivly enough can lead to high losses for the company. This is to big of a risk to take, especially during Black Friday when people are most likely to splurge on shopping. This information can also help companies target certain groups of customers more effectively based on their willingness to pay. By having better targeted ad campaigns, companies can expect sales to go up since the right customers become more aware of the products and sales happening. \n",
    "\n",
    "Another big benefit this model could provide companies insight on which products to stock up on for big sale events. By figuring out which product types have a lot of customers wanting to buy them and their willingess to pay for these products, companies can select the product mix that would maximize profits for them. This would also increase \n",
    "customer satisfaction, as it would look like the companies know exactly what the customers want and how much they want to spend on it. Which would provide many benefits in the long run.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
